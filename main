import json
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup

# Initialize the Chrome driver
chromedriver_path = 'chromedriver.exe'
service = Service(chromedriver_path)
driver = webdriver.Chrome(service=service)
driver.get("https://starfieldwiki.net/wiki/Starfield:Planets")
driver.implicitly_wait(10)

# Extract the table HTML
table = driver.find_element(By.XPATH, "/html/body/div[3]/div[3]/div[4]/div/table[2]")
table_html = table.get_attribute('outerHTML')
driver.quit()

# Parse the HTML with BeautifulSoup
soup = BeautifulSoup(table_html, 'html.parser')

# Extract resource names from the table header
resource_row = soup.find('tr')
resource_names = [cell.text.strip() for cell in resource_row.find_all('th')[2:]]

# Initialize the data dictionary
extracted_data_hej = {}

# Extract rows and populate the data dictionary
rows = soup.find_all('tr')[1:]
for row in rows:
    planet_name, system_name = [cell.text.strip() for cell in row.find_all('td')[:2]]
    planet_name = re.sub(r'\u00a0([A-Za-z])', r' \1', planet_name)
    system_name = re.sub(r'\u00a0([A-Za-z])', r' \1', system_name)
    resources = [resource_names[idx] for idx, cell in enumerate(row.find_all('td')[2:]) if cell.text.strip() == 'âœ”']
    if system_name not in extracted_data_hej:
        extracted_data_hej[system_name] = {}
    extracted_data_hej[system_name][planet_name] = {"resources": resources}

# Write the data to a JSONL file
with open("extracted_data_hej.jsonl", "w", encoding="utf-8") as jsonl_file:
    for system_name, planets in extracted_data_hej.items():
        json_line = json.dumps({system_name: planets})
        jsonl_file.write(json_line + "\n")

print("Data extracted and saved to extracted_data_hej.jsonl file.")
